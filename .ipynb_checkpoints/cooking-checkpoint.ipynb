{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from stemmer import porter_stemmer,snowball_stemmer,Lancaster_stemmer\n",
    "from baseline_rate import Base_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.       You'll need to  create your test set using stratified sampling, to preserve the distribution of recipes falling into different classes\n",
    "\n",
    "b.       You may also want to consider the cooking method as a feature. For instance, Chinese cooking rarely (if ever?) requires baking.\n",
    "\n",
    "c.       You may want to incorporate a cost matrix to assign different penalties for wrongly classifying a recipe as coming from a cuisine that is 'very different' from it's actual cuisine.  \n",
    "\n",
    "d.       What would the misclassification rate be if you were to randomly assign a recipe to a cuisine, according to the proportion of recipes in the training data that fell into that cuisine? This would be a good baseline against which to compare the performance of your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.read_json('/Users/guozhiqi-seven/Downloads/train.json') \n",
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9944, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = pd.read_json('/Users/guozhiqi-seven/Downloads/test.json') \n",
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...\n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]\n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(train_set['ingredients'])) \n",
    "train_set.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Totally 20 types of cusines\n",
    "len(train_set['cuisine'].unique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>italian</th>\n",
       "      <td>0.197063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mexican</th>\n",
       "      <td>0.161865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>southern_us</th>\n",
       "      <td>0.108614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indian</th>\n",
       "      <td>0.075502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chinese</th>\n",
       "      <td>0.067205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>french</th>\n",
       "      <td>0.066526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cajun_creole</th>\n",
       "      <td>0.038870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thai</th>\n",
       "      <td>0.038694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>japanese</th>\n",
       "      <td>0.035777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greek</th>\n",
       "      <td>0.029542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spanish</th>\n",
       "      <td>0.024865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korean</th>\n",
       "      <td>0.020868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vietnamese</th>\n",
       "      <td>0.020742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moroccan</th>\n",
       "      <td>0.020642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>british</th>\n",
       "      <td>0.020214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filipino</th>\n",
       "      <td>0.018982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irish</th>\n",
       "      <td>0.016770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jamaican</th>\n",
       "      <td>0.013225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>russian</th>\n",
       "      <td>0.012294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brazilian</th>\n",
       "      <td>0.011741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cuisine\n",
       "italian       0.197063\n",
       "mexican       0.161865\n",
       "southern_us   0.108614\n",
       "indian        0.075502\n",
       "chinese       0.067205\n",
       "french        0.066526\n",
       "cajun_creole  0.038870\n",
       "thai          0.038694\n",
       "japanese      0.035777\n",
       "greek         0.029542\n",
       "spanish       0.024865\n",
       "korean        0.020868\n",
       "vietnamese    0.020742\n",
       "moroccan      0.020642\n",
       "british       0.020214\n",
       "filipino      0.018982\n",
       "irish         0.016770\n",
       "jamaican      0.013225\n",
       "russian       0.012294\n",
       "brazilian     0.011741"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribution of cuisine in dataset\n",
    "original_dist = (train_set['cuisine'].value_counts() / len(train_set)).to_frame();original_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['greek', 'southern_us', 'filipino', 'indian', 'jamaican', 'spanish',\n",
       "       'italian', 'mexican', 'chinese', 'british', 'thai', 'vietnamese',\n",
       "       'cajun_creole', 'brazilian', 'french', 'japanese', 'irish',\n",
       "       'korean', 'moroccan', 'russian'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['cuisine'].unique()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [romaine lettuce, black olives, grape tomatoes...\n",
       "1    [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2    [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
       "3                  [water, vegetable oil, wheat, salt]\n",
       "4    [black pepper, shallots, cornflour, cayenne pe...\n",
       "Name: ingredients, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['ingredients'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ingredients = train_set['ingredients']\n",
    "ingredients_list = [' '.join(x) for x in ingredients] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['romaine lettuce black olives grape tomatoes garlic pepper purple onion seasoning garbanzo beans feta cheese crumbles',\n",
       " 'plain flour ground pepper salt tomatoes ground black pepper thyme eggs green tomatoes yellow corn meal milk vegetable oil',\n",
       " 'eggs pepper salt mayonaise cooking oil green chilies grilled chicken breasts garlic powder yellow onion soy sauce butter chicken livers',\n",
       " 'water vegetable oil wheat salt',\n",
       " 'black pepper shallots cornflour cayenne pepper onions garlic paste milk butter salt lemon juice water chili powder passata oil ground cumin boneless chicken skinless thigh garam masala double cream natural yogurt bay leaf']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#glimpse of ingredients\n",
    "ingredients_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words\n",
    "* One might using different stemming method by calling porter_stemmer,snowball_stemmer,Lancaster_stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "porter_ingredient = porter_stemmer(ingredients_list)  \n",
    "snowball_ingredient = snowball_stemmer(ingredients_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['romain lettuc black oliv grape tomato garlic pepper purpl onion season garbanzo bean feta chees crumbl',\n",
       " 'plain flour ground pepper salt tomato ground black pepper thyme egg green tomato yellow corn meal milk veget oil',\n",
       " 'egg pepper salt mayonais cook oil green chili grill chicken breast garlic powder yellow onion soy sauc butter chicken liver',\n",
       " 'water veget oil wheat salt',\n",
       " 'black pepper shallot cornflour cayenn pepper onion garlic past milk butter salt lemon juic water chili powder passata oil ground cumin boneless chicken skinless thigh garam masala doubl cream natur yogurt bay leaf']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ingredient after porter stemming\n",
    "porter_ingredient[:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 328053)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(stop_words='english',lowercase = True,ngram_range=(1,3))\n",
    "X_train_tdm = count_vect.fit_transform(ingredients_list) \n",
    "X_train_tdm.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split( \n",
    "    X_train_tdm,train_set['cuisine'], test_size=0.25, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "y_train = labelencoder.fit_transform(y_train) \n",
    "y_valid = labelencoder.transform(y_valid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified sampling, to preserve the distribution of recipes falling into different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>brazilian</th>\n",
       "      <td>0.011633</td>\n",
       "      <td>0.012068</td>\n",
       "      <td>0.011741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>british</th>\n",
       "      <td>0.020315</td>\n",
       "      <td>0.019912</td>\n",
       "      <td>0.020214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cajun_creole</th>\n",
       "      <td>0.039692</td>\n",
       "      <td>0.036404</td>\n",
       "      <td>0.038870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chinese</th>\n",
       "      <td>0.066276</td>\n",
       "      <td>0.069992</td>\n",
       "      <td>0.067205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filipino</th>\n",
       "      <td>0.019242</td>\n",
       "      <td>0.018202</td>\n",
       "      <td>0.018982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>french</th>\n",
       "      <td>0.066644</td>\n",
       "      <td>0.066171</td>\n",
       "      <td>0.066526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greek</th>\n",
       "      <td>0.029266</td>\n",
       "      <td>0.030370</td>\n",
       "      <td>0.029542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indian</th>\n",
       "      <td>0.074422</td>\n",
       "      <td>0.078741</td>\n",
       "      <td>0.075502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irish</th>\n",
       "      <td>0.017030</td>\n",
       "      <td>0.015990</td>\n",
       "      <td>0.016770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>italian</th>\n",
       "      <td>0.197989</td>\n",
       "      <td>0.194288</td>\n",
       "      <td>0.197063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 train      test  original\n",
       "brazilian     0.011633  0.012068  0.011741\n",
       "british       0.020315  0.019912  0.020214\n",
       "cajun_creole  0.039692  0.036404  0.038870\n",
       "chinese       0.066276  0.069992  0.067205\n",
       "filipino      0.019242  0.018202  0.018982\n",
       "french        0.066644  0.066171  0.066526\n",
       "greek         0.029266  0.030370  0.029542\n",
       "indian        0.074422  0.078741  0.075502\n",
       "irish         0.017030  0.015990  0.016770\n",
       "italian       0.197989  0.194288  0.197063"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_distribution = (pd.Series(labelencoder.inverse_transform(y_train)).value_counts()/ len(y_train)).to_frame()\n",
    "test_distribution = (pd.Series(labelencoder.inverse_transform(y_valid)).value_counts() / len(y_valid)).to_frame()\n",
    "cuisine_dist = (pd.concat([train_distribution, test_distribution,original_dist], axis=1))\n",
    "cuisine_dist.columns = ['train','test','original'] ;cuisine_dist[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.001 Score: 0.595032180209\n",
      "C =  0.01 Score: 0.7252614642\n",
      "C =  0.1 Score: 0.783688656476\n",
      "C =  1 Score: 0.791130329847\n",
      "C =  10 Score: 0.786403861625\n",
      "C =  100 Score: 0.781174577635\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "C_penalty = [10**i for i in range(-3,3)]\n",
    "for C_para in C_penalty:\n",
    "    LogReg = LogisticRegression(C=C_para)\n",
    "    LogReg = LogReg.fit(X_train,y_train) \n",
    "    print('C = ',C_para, 'Score:',LogReg.score(X_valid, y_valid) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR performance using porter stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 314884)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tdm_porter = count_vect.fit_transform(porter_ingredient) \n",
    "X_train_tdm_porter.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_porter, X_valid_porter, y_train_porter, y_valid_porter = train_test_split( \n",
    "    X_train_tdm_porter,train_set['cuisine'], test_size=0.25, random_state=0)\n",
    "y_train_porter = labelencoder.fit_transform(y_train)\n",
    "y_valid_porter = labelencoder.transform(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.001 Score: 0.595534995977\n",
      "C =  0.01 Score: 0.726870474658\n",
      "C =  0.1 Score: 0.784593724859\n",
      "C =  1 Score: 0.788817377313\n",
      "C =  10 Score: 0.785800482703\n",
      "C =  100 Score: 0.781275140788\n"
     ]
    }
   ],
   "source": [
    "for C_para in C_penalty:\n",
    "    LogReg = LogisticRegression(C=C_para)\n",
    "    LogReg = LogReg.fit(X_train_porter,y_train_porter)\n",
    "    print('C = ',C_para, 'Score:',LogReg.score(X_valid_porter, y_valid_porter) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.730893000805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "clf_NB = MultinomialNB(alpha=0.01, fit_prior = True)\n",
    "clf_NB.fit(X_train, y_train) \n",
    "\n",
    "predict_nb = clf_NB.predict(X_valid) \n",
    "print (metrics.accuracy_score(y_valid, predict_nb)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7712188254223652"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_clf = SVC(kernel='linear')\n",
    "svc_clf.fit(X_train, y_train)\n",
    "svc_clf.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 328053)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_tdm)\n",
    "X_train_tfidf.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tfidf, X_valid_tfidf, y_train_tfidf, y_valid_tfidf = train_test_split( \n",
    "    X_train_tfidf,train_set['cuisine'], test_size=0.25, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "y_train_tfidf = labelencoder.fit_transform(y_train)\n",
    "y_valid_tfidf = labelencoder.transform(y_valid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.001 Score: 0.194288012872\n",
      "C =  0.01 Score: 0.321198712792\n",
      "C =  0.1 Score: 0.567880128721\n",
      "C =  1 Score: 0.731798069187\n",
      "C =  10 Score: 0.782280772325\n",
      "C =  100 Score: 0.787208366854\n"
     ]
    }
   ],
   "source": [
    "C_penalty = [10**i for i in range(-3,3)]\n",
    "for C_para in C_penalty:\n",
    "    LogReg = LogisticRegression(C=C_para)\n",
    "    LogReg = LogReg.fit(X_train_tfidf,y_train_tfidf)\n",
    "    print('C = ',C_para, 'Score:',LogReg.score(X_valid_tfidf, y_valid_tfidf) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Porter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_tfidf_porter = tfidf_transformer.fit_transform(X_train_tdm_porter)\n",
    "X_train_tfidf_porter.shape \n",
    "X_train_tfidf_porter, X_valid_tfidf_porter, y_train_tfidf_porter, y_valid_tfidf_porter = train_test_split( \n",
    "    X_train_tfidf_porter,train_set['cuisine'], test_size=0.25, random_state=0) \n",
    "y_train_tfidf = labelencoder.fit_transform(y_train_tfidf_porter)\n",
    "y_valid_tfidf = labelencoder.transform(y_valid_tfidf_porter) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.001 Score: 0.194288012872\n",
      "C =  0.01 Score: 0.324215607401\n",
      "C =  0.1 Score: 0.570293644409\n",
      "C =  1 Score: 0.734111021722\n",
      "C =  10 Score: 0.781777956557\n",
      "C =  100 Score: 0.786102172164\n"
     ]
    }
   ],
   "source": [
    "for C_para in C_penalty:\n",
    "    LogReg = LogisticRegression(C=C_para)\n",
    "    LogReg = LogReg.fit(X_train_tfidf_porter,y_train_tfidf_porter)\n",
    "    print('C = ',C_para, 'Score:',LogReg.score(X_valid_tfidf_porter, y_valid_tfidf_porter) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misclassification rate   \n",
    "* For one were to randomly assign a recipe to a cuisine according to the distribution of recipes in the training data, misclassification rate is as high as 0.9, and baseline accuracy is around 0.1, which is much lower than the accuracy of the training model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy is: 0.10100065369336753\n",
      "Misclassification rate: 0.8989993463066325\n"
     ]
    }
   ],
   "source": [
    "base_accuracy = Base_accuracy(train_set)\n",
    "print('Baseline accuracy is:', base_accuracy) \n",
    "print('Misclassification rate:',1-base_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
